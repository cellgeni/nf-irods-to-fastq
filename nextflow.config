// Global default params, used in configs
params {
    help = false
    // A metadata CSV with the sample IDs, and possibly other iRODS parameters
    // Header relevant, as specifies iRODS metadata field names
    samples = 'examples/samples.csv'
    // Other potential arguments, though not mandatory
    // Where to put the output (publish folder path)
    publish_dir = "results"
    // By default Samtools checks the reference MD5 sums (@SQ “M5” auxiliary tag) in the directory pointed to by 
    // $REF_PATH environment variable (if it exists), falling back to querying the European Bioinformatics Institute (EBI)
    // reference genome server, and further falling back to the @SQ “UR” field if these are not found.
    REF_PATH="/lustre/scratch125/core/sciops_repository/cram_cache/%2s/%2s/%s:/lustre/scratch126/core/sciops_repository/cram_cache/%2s/%2s/%s:URL=http:://sf2-farm-srv1.internal.sanger.ac.uk::8000/%s"
    index_format = "i*i*"
    only_meta = false
    from_meta = null
}

// Singularity environment parameters
singularity {
  enabled     = true
  autoMounts  = true
  runOptions  = '-B /lustre,/nfs'
}

executor {
  $lsf {
      perJobMemLimit = true 
  }

  $local {
      cpus = 4
      memory = '2 GB'
  }
}

process {
    withLabel: normal {
        executor = 'lsf'
        queue  = "normal"
        cpus   = 1
        memory = 2.GB
    }
    withLabel: normal4core {
        executor = 'lsf'
        queue  = "normal"
        cpus   = 4
        memory = 2.GB
    }
    withLabel: easy {
        executor = 'local'
    }
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

// Capturing Nextflow log files into a 'reports' directory
import java.time.*
Date now = new Date()

params {
    tracedir = "reports"
    timestamp = now.format("yyyyMMdd-HH-mm-ss")
}

timeline {
    enabled = true
    file = "${params.tracedir}/${params.timestamp}_timeline.html"
}
report {
    enabled = true
    file = "${params.tracedir}/${params.timestamp}_report.html"
}

// Ensure work directories and removed on successfull pipeline execution
//cleanup = true

